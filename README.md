[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-22041afd0340ce965d47ae6ef1cefeee28c7c493a6346c4f15d667ab976d596c.svg)](https://classroom.github.com/a/QODoQuhO)
# Распределенная обработка текстовых данных с использованием брокера сообщений

## Цель задания:
Реализовать распределённую систему обработки текстовых данных, где секции текста рассылаются на обработку через брокер сообщений (message broker). Несколько воркеров параллельно обрабатывают секции и отправляют результаты на агрегатор. Воркеры выполняют набор задач

## Шаги выполнения:

### Рекомендуемый брокер
RabbitMQ --- прост в развёртывании, понятная модель exchange/queue, есть клиенты для Java и C++. Подходит для предлагаемой задачи.

### Подготовка данных:
Загрузите или создайте набор текстовых данных. Это могут быть, например, книги, статьи или большой корпус текста. Разделите данные на секции для распределения между узлами.

### Разработка приложения:
Общая задача: Необходимо решить следующие задачи для обработки текстовых данных:
* Подсчёт количества слов.
* Поиск N наиболее часто встречающихся слов (top-N).
* Простой анализ тональности — выбрать и реализовать один из подходов:
  * Лексиконный (словарь положительных/отрицательных слов) — прост в реализации. 
  * Наивный байес/предобученная модель.
* Замена всех имён в тексте на заданное подстановку. Для простоты можно:
  * Использовать регулярные выражения (заглавные слова, контекст) или 
  * Подключить лёгкую NER-библиотеку (в Java — OpenNLP или StanfordNLP — опционально).
* Сортировка предложений по длине (в символах) и возврат отсортированного списка.

### Структура системы (компоненты)
1. Producer / Splitter 
   * Читает корпус, разбивает на секции (например, по параграфам, по N предложений или по байтам). 
   * Отправляет задания в очередь/exchange (сообщения с id задания и секцией текста).

2. Worker (несколько экземпляров)
   * Подписывается на очередь задач. 
   * Обрабатывает секцию и отправляет результат в очередь результатов/на агрегатор.

3. Aggregator / Collector
   * Получает частичные результаты от всех воркеров. 
   * Агрегирует: суммирует word counts, объединяет топ-N (merge топов), усредняет/агрегирует тональность, собирает модифицированный текст/заменённые имена (если нужно), объединяет отсортированные предложения (опционально — сохраняет per-section).

4. Result sink / storage 
   * Сохраняет финальные результаты в файл/JSON для отчёта.

### Формат сообщений можете придумать самостоятельно


## Эксперименты и анализ результатов:
Оцените масштабируемость приложения. Используйте различные объемы данных и количество воркеров для определения, насколько эффективно приложение масштабируется.
